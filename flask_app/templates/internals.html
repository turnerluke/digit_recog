{% extends "base.html" %}

	{% block title %}
		Web App Internals
	{% endblock %}
	
	{% block content %}
		<div class="container">

			<h1>
				Workflow
			</h1>
			<p>
				The Flask app is rendered on the Heroku server. When the user draws a digit and selects "Predict", JavaScript encodes the canvas into a base 64 image, which is passed to Python.
				In Python, the image is processed by CV2 and reshaped to a numpy array, which fits the input of the model.
				The processed image is passed to the model, and the output is dumped into a JSON to pass back to the JavaScript code.
				The JSON of the model prediction is then parsed back to HTML for the web page, and a descriptive report on the prediction is created.
			</p>

			<h2>
				Base HTML
			</h2>
			<p>
				All pages inherit the <a href="https://github.com/turnerluke/digit_recog/blob/main/templates/base.html">base.html</a> file.
				This parent HTML file sets the favicon, the css styles, the bootstrapped navigation bar, and the footer.
			</p>


			<h2>
				Drawing the Digits
			</h2>
			<p>
				The HTML canvas interfaces with <a href="https://github.com/turnerluke/digit_recog/blob/main/static/draw.js">draw.js</a> to accept the user's mouse inputs into an array.
			</p>

			<h2>
				Processing the Image
			</h2>
			<p>
				The drawn digit is passed to <a href=h"ttps://github.com/turnerluke/digit_recog/blob/main/app.py">app.py</a>, where it is passed to <a href="https://github.com/turnerluke/digit_recog/blob/main/functions.py">functions.py</a> and preprocessed to fit the input of the LeNet-5 2.0 model.
				The image is processed as follows:
				<ul>
					<li>Decode from base 64</li>
					<li>Convert to a numpy array</li>
					<li>Convert to black and white (remove 3rd dimension)</li>
					<li>Resize to size (32, 32) with cv2</li>
					<li>Scale to zero mean and unity standard deviation</li>
					<li>Expand dimensions to (None, 32, 32, None)</li>
				</ul>
			</p>

			<h2>
				Model Prediction
			</h2>
			<p>
				The CNN, which was created in Keras, conveniently accepts the image array with <code>model.predict(arr)</code>. The output of the model is de-one-hot encoded with <code>np.argsort(output)</code>, and the prediction out puts are calculated from this output.
			</p>

			<h2>
				Prediction Visualizations
			</h2>
			<p>
				The web-app presents the top prediction of the model, and a table of the top three predictions, both as HTML elements.
				Lastly, a bar graph of the model outputs * 100% is displayed.
				This graph is created by passing the model output to <a href="https://github.com/turnerluke/digit_recog/blob/main/functions.py">functions.py</a>, where a seaborn barchart is plotted on a matplotlib figure.
				The figure is encoded to base 64, and returned to <a href=h"ttps://github.com/turnerluke/digit_recog/blob/main/app.py">app.py</a>, and added to the json of the predictions.
				These deliverables from the model output are passed to <a href="https://github.com/turnerluke/digit_recog/blob/main/static/draw.js">draw.js</a> where they are parsed into <a href="https://github.com/turnerluke/digit_recog/blob/main/templates/index.html">index.html</a>, the main webpage.
			</p>

    		</div>

	{% endblock %}
	
